{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e39f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, glob, scipy.io, time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pywt\n",
    "from scipy.signal import resample_poly\n",
    "from numpy.polynomial.polynomial import Polynomial\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv1D, MaxPooling1D, GlobalAveragePooling1D,\n",
    "                                     Dense, Dropout, Multiply, Add, LayerNormalization,\n",
    "                                     Lambda, BatchNormalization, SpatialDropout1D,\n",
    "                                     Concatenate, MultiHeadAttention, Layer)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# --- GPU setup ---\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"✅ GPU detected: {gpus[0]}\")\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "else:\n",
    "    print(\"⚠️ No GPU found. Training might be slow.\")\n",
    "\n",
    "# --- Constants ---\n",
    "ORIG_FS = 256  # Original sampling frequency\n",
    "TARGET_FS = 34.3  # Target sampling frequency\n",
    "EPOCH_SAMPLES = 1024  # Samples per epoch at TARGET_FS\n",
    "TOTAL_HOURS = 10\n",
    "EPOCHS_PER_HOUR = int(3600 * TARGET_FS / EPOCH_SAMPLES)  # epochs in 1 hour\n",
    "TOTAL_EPOCHS = TOTAL_HOURS * EPOCHS_PER_HOUR  # fixed length for each subject\n",
    "K_FOLDS = 5  # Number of folds for k-fold cross-validation\n",
    "NUM_CLASSES = 5  # Number of sleep stages\n",
    "WAVELET = 'db4'  # Wavelet type for DWT\n",
    "\n",
    "# --- Preprocessing functions ---\n",
    "\n",
    "def wavelet_denoise(signal, wavelet=WAVELET, level=4):\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "    threshold = np.std(coeffs[-1]) * np.sqrt(2 * np.log(len(signal)))\n",
    "    coeffs[1:] = [pywt.threshold(c, threshold, mode='soft') for c in coeffs[1:]]\n",
    "    return pywt.waverec(coeffs, wavelet)\n",
    "\n",
    "def poly_detrend(signal, degree=10):\n",
    "    x = np.arange(len(signal))\n",
    "    coefs = Polynomial.fit(x, signal, degree).convert().coef\n",
    "    trend = np.polyval(coefs[::-1], x)\n",
    "    return signal - trend\n",
    "\n",
    "def min_max_norm(signal):\n",
    "    min_val = np.min(signal)\n",
    "    max_val = np.max(signal)\n",
    "    if max_val - min_val == 0:\n",
    "        return signal * 0\n",
    "    return (signal - min_val) / (max_val - min_val)\n",
    "\n",
    "def preprocess_ppg_signal(ppg_signal, orig_fs=ORIG_FS, target_fs=TARGET_FS,\n",
    "                         epoch_samples=EPOCH_SAMPLES, total_epochs=TOTAL_EPOCHS):\n",
    "    denoised = wavelet_denoise(ppg_signal)\n",
    "    detrended = poly_detrend(denoised)\n",
    "    normalized = min_max_norm(detrended)\n",
    "    up = int(target_fs * 1000)\n",
    "    down = int(orig_fs * 1000)\n",
    "    gcd = np.gcd(up, down)\n",
    "    up //= gcd\n",
    "    down //= gcd\n",
    "    resampled = resample_poly(normalized, up, down)\n",
    "    total_samples = epoch_samples * total_epochs\n",
    "    if len(resampled) > total_samples:\n",
    "        resampled = resampled[:total_samples]\n",
    "    elif len(resampled) < total_samples:\n",
    "        pad_len = total_samples - len(resampled)\n",
    "        resampled = np.pad(resampled, (0, pad_len), 'constant')\n",
    "    epochs = resampled.reshape(total_epochs, epoch_samples)\n",
    "    mask = np.array([0 if np.sum(e) == 0 else 1 for e in epochs])\n",
    "    return epochs, mask\n",
    "\n",
    "# --- Time-Frequency Mixup Augmentation ---\n",
    "\n",
    "def time_frequency_mixup(X, y, alpha=0.2):\n",
    "    indices = np.random.permutation(len(X))\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    X_mix = lam * X + (1 - lam) * X[indices]\n",
    "    y_mix = lam * y + (1 - lam) * y[indices]\n",
    "    return X_mix, y_mix\n",
    "\n",
    "# --- Load and preprocess data for each patient type ---\n",
    "\n",
    "patient_types = ['normal', 'apnea', 'plm', 'insomnia']\n",
    "data_paths = {\n",
    "    'normal': r\"D:\\abhishek_extracted\\normal\",\n",
    "    'apnea': r\"D:\\abhishek_extracted\\apnea\",\n",
    "    'plm': r\"D:\\abhishek_extracted\\plm\",\n",
    "    'insomnia': r\"D:\\abhishek_extracted\\insomnia\"\n",
    "}\n",
    "\n",
    "datasets = {}\n",
    "for ptype in patient_types:\n",
    "    mat_files = sorted(glob.glob(os.path.join(data_paths[ptype], \"*.mat\")))[:39]\n",
    "    X_epochs_list = []\n",
    "    y_epochs_list = []\n",
    "    mask_list = []\n",
    "    for file in mat_files:\n",
    "        mat = scipy.io.loadmat(file)\n",
    "        raw_signal = mat['ppg_signals'].flatten()\n",
    "        sleep_labels = mat['sleep_stages'].flatten()\n",
    "        epochs, mask = preprocess_ppg_signal(raw_signal)\n",
    "        if len(sleep_labels) > epochs.shape[0]:\n",
    "            sleep_labels = sleep_labels[:epochs.shape[0]]\n",
    "        elif len(sleep_labels) < epochs.shape[0]:\n",
    "            pad_len = epochs.shape[0] - len(sleep_labels)\n",
    "            sleep_labels = np.pad(sleep_labels, (0, pad_len), constant_values=-1)\n",
    "        X_epochs_list.append(epochs)\n",
    "        y_epochs_list.append(sleep_labels)\n",
    "        mask_list.append(mask)\n",
    "    X_all = np.vstack(X_epochs_list)\n",
    "    y_all = np.concatenate(y_epochs_list)\n",
    "    mask_all = np.concatenate(mask_list)\n",
    "    valid_idx = (y_all != -1) & (mask_all == 1)\n",
    "    datasets[ptype] = {'X': X_all[valid_idx], 'y': y_all[valid_idx]}\n",
    "    print(f\"{ptype.capitalize()} - Total epochs: {X_all.shape[0]}, Valid epochs: {len(datasets[ptype]['y'])}\")\n",
    "\n",
    "# --- Hybrid Loss Function ---\n",
    "\n",
    "def class_balanced_focal_loss(gamma=1.5, beta=0.9):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        modulating_factor = tf.math.pow(1.0 - y_pred, gamma)\n",
    "        # Class-balanced weights based on effective number of samples\n",
    "        class_counts = tf.reduce_sum(y_true, axis=0)\n",
    "        effective_num = 1.0 - tf.math.pow(beta, class_counts)\n",
    "        weights = (1.0 - beta) / (effective_num + epsilon)\n",
    "        weights = weights / tf.reduce_sum(weights) * NUM_CLASSES\n",
    "        loss = weights * modulating_factor * ce\n",
    "        return tf.reduce_mean(tf.reduce_sum(loss, axis=1))\n",
    "    return loss_fn\n",
    "\n",
    "# --- Spectral Gating Layer ---\n",
    "\n",
    "class SpectralGatingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SpectralGatingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gate = Dense(input_shape[-1], activation='sigmoid')\n",
    "        super(SpectralGatingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        gate = self.gate(GlobalAveragePooling1D()(inputs))\n",
    "        gate = Lambda(lambda x: tf.expand_dims(x, 1))(gate)\n",
    "        return Multiply()([inputs, gate])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(SpectralGatingLayer, self).get_config()\n",
    "        return config\n",
    "\n",
    "# --- Model definition: SleepWaveNet ---\n",
    "\n",
    "def build_sleepwavenet(input_shape):\n",
    "    # Initialize model with L2 regularization\n",
    "    reg = l2(1e-4)\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Initial dilated convolution block\n",
    "    x = Conv1D(32, 7, padding='causal', activation='relu', dilation_rate=1, kernel_regularizer=reg)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    # Inception-Wave block: multi-scale dilated convolutions\n",
    "    branch1 = Conv1D(16, 3, padding='causal', activation='relu', dilation_rate=1, kernel_regularizer=reg)(x)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    branch2 = Conv1D(16, 3, padding='causal', activation='relu', dilation_rate=2, kernel_regularizer=reg)(x)\n",
    "    branch2 = BatchNormalization()(branch2)\n",
    "    branch3 = Conv1D(16, 3, padding='causal', activation='relu', dilation_rate=4, kernel_regularizer=reg)(x)\n",
    "    branch3 = BatchNormalization()(branch3)\n",
    "    x = Concatenate()([branch1, branch2, branch3])\n",
    "    \n",
    "    # Local attention: focus on short-term patterns\n",
    "    local_attn = MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "    x = Add()([x, local_attn])\n",
    "    x = LayerNormalization()(x)\n",
    "    \n",
    "    # Spectral gating: emphasize relevant frequency components\n",
    "    x = SpectralGatingLayer()(x)\n",
    "    \n",
    "    # Second dilated convolution block\n",
    "    res = Conv1D(48, 1, padding='causal', kernel_regularizer=reg)(x)\n",
    "    res = BatchNormalization()(res)\n",
    "    x = Conv1D(48, 5, padding='causal', activation='relu', dilation_rate=2, kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    res = MaxPooling1D(2)(res)\n",
    "    x = Add()([x, res])\n",
    "    x = LayerNormalization()(x)\n",
    "    \n",
    "    # Global attention: capture long-range dependencies\n",
    "    global_attn = MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "    x = Add()([x, global_attn])\n",
    "    x = LayerNormalization()(x)\n",
    "    \n",
    "    # Classification head\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='relu', kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# --- Training loop for each patient type ---\n",
    "\n",
    "results = {}\n",
    "normal_weights = None\n",
    "\n",
    "for ptype in patient_types:\n",
    "    print(f\"\\n=== Training for {ptype.capitalize()} Dataset ===\")\n",
    "    X_all, y_all = datasets[ptype]['X'], datasets[ptype]['y']\n",
    "    \n",
    "    # Augmentation\n",
    "    X_aug, y_aug = time_frequency_mixup(X_all, tf.keras.utils.to_categorical(y_all, NUM_CLASSES))\n",
    "    X_aug = np.array([min_max_norm(x) for x in X_aug])  # Re-normalize after mixup\n",
    "    \n",
    "    # Standardization\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_aug)\n",
    "    \n",
    "    # SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_res, y_res = smote.fit_resample(X_scaled, np.argmax(y_aug, axis=1))\n",
    "    \n",
    "    # Class weights\n",
    "    class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_res), y=y_res)\n",
    "    class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "    \n",
    "    # K-Fold Cross-Validation\n",
    "    skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "    fold_metrics = {\n",
    "        'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': [],\n",
    "        'kappa': [], 'classification_reports': [], 'confusion_matrices': []\n",
    "    }\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X_res, y_res)):\n",
    "        X_train, X_test = X_res[train_idx], X_res[test_idx]\n",
    "        y_train, y_test = y_res[train_idx], y_res[test_idx]\n",
    "        \n",
    "        X_train = X_train[..., np.newaxis]\n",
    "        X_test = X_test[..., np.newaxis]\n",
    "        y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "        y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=NUM_CLASSES)\n",
    "        \n",
    "        # Build model\n",
    "        model = build_sleepwavenet((X_train.shape[1], 1))\n",
    "        \n",
    "        # Load Normal weights for non-Normal datasets\n",
    "        if ptype != 'normal' and normal_weights is not None:\n",
    "            model.set_weights(normal_weights)\n",
    "        \n",
    "        model.compile(optimizer=Adam(1e-4),\n",
    "                      loss=class_balanced_focal_loss(gamma=1.5, beta=0.9),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        callbacks = [\n",
    "            EarlyStopping(patience=10, restore_best_weights=True),\n",
    "            ModelCheckpoint(f\"best_sleepwavenet_{ptype}_fold_{fold+1}.keras\", save_best_only=True),\n",
    "            ReduceLROnPlateau(patience=3, factor=0.5)\n",
    "        ]\n",
    "        \n",
    "        # Train\n",
    "        history = model.fit(X_train, y_train_cat, validation_data=(X_test, y_test_cat),\n",
    "                            epochs=100, batch_size=64, class_weight=class_weight_dict,\n",
    "                            callbacks=callbacks, verbose=1)\n",
    "        \n",
    "        # Save weights for Normal dataset\n",
    "        if ptype == 'normal':\n",
    "            normal_weights = model.get_weights()\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_cls = np.argmax(y_pred, axis=1)\n",
    "        y_true_cls = np.argmax(y_test_cat, axis=1)\n",
    "        \n",
    "        fold_metrics['accuracy'].append(history.history['accuracy'])\n",
    "        fold_metrics['val_accuracy'].append(history.history['val_accuracy'])\n",
    "        fold_metrics['loss'].append(history.history['loss'])\n",
    "        fold_metrics['val_loss'].append(history.history['val_loss'])\n",
    "        fold_metrics['kappa'].append(cohen_kappa_score(y_true_cls, y_pred_cls))\n",
    "        fold_metrics['classification_reports'].append(classification_report(y_true_cls, y_pred_cls, output_dict=True))\n",
    "        fold_metrics['confusion_matrices'].append(confusion_matrix(y_true_cls, y_pred_cls))\n",
    "        \n",
    "        print(f\"\\nFold {fold+1} Classification Report:\")\n",
    "        print(classification_report(y_true_cls, y_pred_cls))\n",
    "        print(f\"Fold {fold+1} Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_true_cls, y_pred_cls))\n",
    "        print(f\"Fold {fold+1} Cohen Kappa Score: {fold_metrics['kappa'][-1]:.4f}\")\n",
    "    \n",
    "    # Aggregate metrics\n",
    "    mean_val_accuracy = np.mean([max(fold_metrics['val_accuracy'][i]) for i in range(K_FOLDS)])\n",
    "    mean_kappa = np.mean(fold_metrics['kappa'])\n",
    "    \n",
    "    results[ptype] = {\n",
    "        'mean_val_accuracy': mean_val_accuracy,\n",
    "        'mean_kappa': mean_kappa,\n",
    "        'fold_metrics': fold_metrics\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n=== {ptype.capitalize()} K-Fold Results ===\")\n",
    "    print(f\"Mean Validation Accuracy: {mean_val_accuracy:.4f}\")\n",
    "    print(f\"Mean Cohen Kappa Score: {mean_kappa:.4f}\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    for fold in range(K_FOLDS):\n",
    "        plt.plot(fold_metrics['accuracy'][fold], label=f'train fold {fold+1}')\n",
    "        plt.plot(fold_metrics['val_accuracy'][fold], label=f'val fold {fold+1}')\n",
    "    plt.title(f\"{ptype.capitalize()} Accuracy Across Folds\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    for fold in range(K_FOLDS):\n",
    "        plt.plot(fold_metrics['loss'][fold], label=f'train fold {fold+1}')\n",
    "        plt.plot(fold_metrics['val_loss'][fold], label=f'val fold {fold+1}')\n",
    "    plt.title(f\"{ptype.capitalize()} Loss Across Folds\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save model\n",
    "    model.save(f\"sleepwavenet_{ptype}_model.keras\")\n",
    "    \n",
    "    # Export TFLite\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    with open(f\"sleepwavenet_{ptype}_model.tflite\", \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "# --- Summary of Results ---\n",
    "print(\"\\n=== Final Summary Across Patient Types ===\")\n",
    "for ptype in patient_types:\n",
    "    print(f\"{ptype.capitalize()}:\")\n",
    "    print(f\"  Mean Validation Accuracy: {results[ptype]['mean_val_accuracy']:.4f}\")\n",
    "    print(f\"  Mean Cohen Kappa Score: {results[ptype]['mean_kappa']:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\n⏱️ Total training time: {(end_time - start_time)/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d3c55aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU detected: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 370\u001b[0m\n\u001b[0;32m    368\u001b[0m raw_signal \u001b[38;5;241m=\u001b[39m mat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mppg_signals\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    369\u001b[0m sleep_labels \u001b[38;5;241m=\u001b[39m mat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep_stages\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m--> 370\u001b[0m epochs, mask \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_ppg_signal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_signal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sleep_labels) \u001b[38;5;241m>\u001b[39m epochs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    372\u001b[0m     sleep_labels \u001b[38;5;241m=\u001b[39m sleep_labels[:epochs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]]\n",
      "Cell \u001b[1;32mIn[3], line 75\u001b[0m, in \u001b[0;36mpreprocess_ppg_signal\u001b[1;34m(ppg_signal, orig_fs, target_fs, epoch_samples, total_epochs)\u001b[0m\n\u001b[0;32m     73\u001b[0m     resampled \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(resampled, (\u001b[38;5;241m0\u001b[39m, total_samples \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(resampled)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     74\u001b[0m epochs \u001b[38;5;241m=\u001b[39m resampled\u001b[38;5;241m.\u001b[39mreshape(total_epochs, epoch_samples)\n\u001b[1;32m---> 75\u001b[0m spectral_epochs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([graph_spectral_decomposition(e) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m epochs])\n\u001b[0;32m     76\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m epochs])\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spectral_epochs, mask\n",
      "Cell \u001b[1;32mIn[3], line 75\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     73\u001b[0m     resampled \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(resampled, (\u001b[38;5;241m0\u001b[39m, total_samples \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(resampled)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     74\u001b[0m epochs \u001b[38;5;241m=\u001b[39m resampled\u001b[38;5;241m.\u001b[39mreshape(total_epochs, epoch_samples)\n\u001b[1;32m---> 75\u001b[0m spectral_epochs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mgraph_spectral_decomposition\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m epochs])\n\u001b[0;32m     76\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m epochs])\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spectral_epochs, mask\n",
      "Cell \u001b[1;32mIn[3], line 55\u001b[0m, in \u001b[0;36mgraph_spectral_decomposition\u001b[1;34m(signal, k)\u001b[0m\n\u001b[0;32m     53\u001b[0m             G\u001b[38;5;241m.\u001b[39madd_edge(i, j, weight\u001b[38;5;241m=\u001b[39mweight)\n\u001b[0;32m     54\u001b[0m L \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mlaplacian_matrix(G)\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m---> 55\u001b[0m eigvals, eigvecs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m low \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(eigvecs[:, :\u001b[38;5;241m2\u001b[39m], eigvecs[:, :\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m signal)\n\u001b[0;32m     57\u001b[0m mid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(eigvecs[:, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m5\u001b[39m], eigvecs[:, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m signal)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36meigh\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\linalg\\linalg.py:1465\u001b[0m, in \u001b[0;36meigh\u001b[1;34m(a, UPLO)\u001b[0m\n\u001b[0;32m   1462\u001b[0m     gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39meigh_up\n\u001b[0;32m   1464\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->dD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->dd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1465\u001b[0m w, vt \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1466\u001b[0m w \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1467\u001b[0m vt \u001b[38;5;241m=\u001b[39m vt\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, glob, scipy.io, time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from scipy.fft import fft\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import shap\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv1D, Dense, Dropout, Multiply, Add,\n",
    "                                     LayerNormalization, Lambda, BatchNormalization,\n",
    "                                     SpatialDropout1D, Concatenate, MultiHeadAttention, Layer)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# --- GPU setup ---\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"✅ GPU detected: {gpus[0]}\")\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "else:\n",
    "    print(\"⚠️ No GPU found. Training might be slow.\")\n",
    "\n",
    "# --- Constants ---\n",
    "ORIG_FS = 256\n",
    "TARGET_FS = 34.3\n",
    "EPOCH_SAMPLES = 1024\n",
    "TOTAL_HOURS = 10\n",
    "EPOCHS_PER_HOUR = int(3600 * TARGET_FS / EPOCH_SAMPLES)\n",
    "TOTAL_EPOCHS = TOTAL_HOURS * EPOCHS_PER_HOUR\n",
    "K_FOLDS = 5\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "# --- Graph Spectral Decomposition ---\n",
    "\n",
    "def graph_spectral_decomposition(signal, k=5):\n",
    "    G = nx.Graph()\n",
    "    n = len(signal)\n",
    "    for i in range(n):\n",
    "        G.add_node(i, value=signal[i])\n",
    "        for j in range(max(0, i-k), min(n, i+k+1)):\n",
    "            if i != j:\n",
    "                weight = np.exp(-((signal[i] - signal[j])**2) / (2 * 0.1**2))\n",
    "                G.add_edge(i, j, weight=weight)\n",
    "    L = nx.laplacian_matrix(G).toarray()\n",
    "    eigvals, eigvecs = np.linalg.eigh(L)\n",
    "    low = np.dot(eigvecs[:, :2], eigvecs[:, :2].T @ signal)\n",
    "    mid = np.dot(eigvecs[:, 2:5], eigvecs[:, 2:5].T @ signal)\n",
    "    high = np.dot(eigvecs[:, 5:10], eigvecs[:, 5:10].T @ signal)\n",
    "    return np.stack([low, mid, high], axis=-1)\n",
    "\n",
    "def preprocess_ppg_signal(ppg_signal, orig_fs=ORIG_FS, target_fs=TARGET_FS,\n",
    "                         epoch_samples=EPOCH_SAMPLES, total_epochs=TOTAL_EPOCHS):\n",
    "    up = int(target_fs * 1000)\n",
    "    down = int(orig_fs * 1000)\n",
    "    gcd = np.gcd(up, down)\n",
    "    up //= gcd\n",
    "    down //= gcd\n",
    "    resampled = resample_poly(ppg_signal, up, down)\n",
    "    total_samples = epoch_samples * total_epochs\n",
    "    if len(resampled) > total_samples:\n",
    "        resampled = resampled[:total_samples]\n",
    "    elif len(resampled) < total_samples:\n",
    "        resampled = np.pad(resampled, (0, total_samples - len(resampled)), 'constant')\n",
    "    epochs = resampled.reshape(total_epochs, epoch_samples)\n",
    "    spectral_epochs = np.array([graph_spectral_decomposition(e) for e in epochs])\n",
    "    mask = np.array([0 if np.sum(e) == 0 else 1 for e in epochs])\n",
    "    return spectral_epochs, mask\n",
    "\n",
    "# --- Adversarial Frequency Mixup ---\n",
    "\n",
    "class PPGGAN:\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.gan = self.build_gan()\n",
    "\n",
    "    def build_generator(self):\n",
    "        noise = Input(shape=(100,))\n",
    "        label = Input(shape=(self.num_classes,))\n",
    "        x = Concatenate()([noise, label])\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dense(np.prod(self.input_shape), activation='tanh')(x)\n",
    "        x = tf.keras.layers.Reshape(self.input_shape)(x)\n",
    "        return Model([noise, label], x)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        inputs = Input(shape=self.input_shape)\n",
    "        label = Input(shape=(self.num_classes,))\n",
    "        x = Conv1D(32, 7, padding='same', activation='relu')(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling1D(2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Concatenate()([x, label])\n",
    "        x = Dense(64, activation='relu')(x)\n",
    "        x = Dense(1, activation='sigmoid')(x)\n",
    "        return Model([inputs, label], x)\n",
    "\n",
    "    def build_gan(self):\n",
    "        self.discriminator.trainable = False\n",
    "        noise = Input(shape=(100,))\n",
    "        label = Input(shape=(self.num_classes,))\n",
    "        gen_sample = self.generator([noise, label])\n",
    "        validity = self.discriminator([gen_sample, label])\n",
    "        return Model([noise, label], validity)\n",
    "\n",
    "    def train(self, X, y, epochs=100):\n",
    "        optimizer = Adam(1e-4)\n",
    "        self.discriminator.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "        self.gan.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "        batch_size = 64\n",
    "        for epoch in range(epochs):\n",
    "            idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "            real_samples = X[idx]\n",
    "            real_labels = y[idx]\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "            fake_samples = self.generator.predict([noise, real_labels], verbose=0)\n",
    "            d_loss_real = self.discriminator.train_on_batch([real_samples, real_labels], np.ones(batch_size))\n",
    "            d_loss_fake = self.discriminator.train_on_batch([fake_samples, real_labels], np.zeros(batch_size))\n",
    "            g_loss = self.gan.train_on_batch([noise, real_labels], np.ones(batch_size))\n",
    "\n",
    "def adversarial_frequency_mixup(X, y, alpha=0.2):\n",
    "    gan = PPGGAN(input_shape=(X.shape[1], X.shape[2]), num_classes=NUM_CLASSES)\n",
    "    minority_classes = np.where(np.bincount(np.argmax(y, axis=1)) < np.median(np.bincount(np.argmax(y, axis=1))))[0]\n",
    "    X_minority = X[np.isin(np.argmax(y, axis=1), minority_classes)]\n",
    "    y_minority = y[np.isin(np.argmax(y, axis=1), minority_classes)]\n",
    "    gan.train(X_minority, y_minority, epochs=50)\n",
    "    synthetic_samples = []\n",
    "    synthetic_labels = []\n",
    "    for cls in minority_classes:\n",
    "        cls_one_hot = np.zeros(NUM_CLASSES)\n",
    "        cls_one_hot[cls] = 1\n",
    "        noise = np.random.normal(0, 1, (1000, 100))\n",
    "        cls_labels = np.repeat([cls_one_hot], 1000, axis=0)\n",
    "        synth = gan.generator.predict([noise, cls_labels], verbose=0)\n",
    "        synthetic_samples.append(synth)\n",
    "        synthetic_labels.append(cls_labels)\n",
    "    X_synth = np.vstack(synthetic_samples)\n",
    "    y_synth = np.vstack(synthetic_labels)\n",
    "    X_aug = np.vstack([X, X_synth])\n",
    "    y_aug = np.vstack([y, y_synth])\n",
    "    indices = np.random.permutation(len(X_aug))\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    X_mix = lam * X_aug + (1 - lam) * X_aug[indices]\n",
    "    y_mix = lam * y_aug + (1 - lam) * y_aug[indices]\n",
    "    return X_mix, y_mix\n",
    "\n",
    "# --- Contrastive Temporal Learning ---\n",
    "\n",
    "def contrastive_loss(y_true, y_pred, margin=1.0):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    square_pred = tf.square(y_pred)\n",
    "    margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
    "    return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def build_contrastive_backbone(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(32, 7, padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Conv1D(32, 5, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    return Model(inputs, x)\n",
    "\n",
    "def pretrain_contrastive(X, epochs=50):\n",
    "    input_shape = (X.shape[1], X.shape[2])\n",
    "    backbone = build_contrastive_backbone(input_shape)\n",
    "    inputs1 = Input(shape=input_shape)\n",
    "    inputs2 = Input(shape=input_shape)\n",
    "    emb1 = backbone(inputs1)\n",
    "    emb2 = backbone(inputs2)\n",
    "    distance = tf.reduce_sum(tf.square(emb1 - emb2), axis=-1)\n",
    "    model = Model([inputs1, inputs2], distance)\n",
    "    model.compile(optimizer=Adam(1e-4), loss=contrastive_loss)\n",
    "    batch_size = 64\n",
    "    for epoch in range(epochs):\n",
    "        idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "        X1 = X[idx]\n",
    "        X2 = X[np.random.permutation(idx)]\n",
    "        y = np.random.randint(0, 2, batch_size).astype(np.float32)\n",
    "        X2[y == 1] = X1[y == 1]\n",
    "        model.train_on_batch([X1, X2], y)\n",
    "    return backbone\n",
    "\n",
    "# --- Dynamic Imbalanced Loss ---\n",
    "\n",
    "def dynamic_imbalanced_loss(gamma=1.5, beta=0.9):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        modulating_factor = tf.math.pow(1.0 - y_pred, gamma)\n",
    "        class_counts = tf.reduce_sum(y_true, axis=0)\n",
    "        effective_num = 1.0 - tf.math.pow(beta, class_counts)\n",
    "        weights = (1.0 - beta) / (effective_num + epsilon)\n",
    "        weights = weights / tf.reduce_sum(weights) * NUM_CLASSES\n",
    "        loss = weights * modulating_factor * ce\n",
    "        overconfidence = tf.reduce_mean(tf.maximum(y_pred - 0.9, 0))\n",
    "        return tf.reduce_mean(tf.reduce_sum(loss, axis=1)) + 0.1 * overconfidence\n",
    "    return loss_fn\n",
    "\n",
    "# --- Graph Convolutional Layer ---\n",
    "\n",
    "class GraphConvLayer(Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(GraphConvLayer, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='kernel', shape=(input_shape[-1], self.filters),\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        super(GraphConvLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        adj = tf.reduce_mean(inputs, axis=-1)  # Simplified adjacency\n",
    "        adj = tf.nn.softmax(adj, axis=-1)\n",
    "        x = tf.einsum('bnt,bnf->btf', adj, inputs)\n",
    "        return tf.matmul(x, self.W)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GraphConvLayer, self).get_config()\n",
    "        config.update({\"filters\": self.filters})\n",
    "        return config\n",
    "\n",
    "# --- NeuroWaveSleep Architecture ---\n",
    "\n",
    "def build_neurowavesleep(input_shape, backbone=None):\n",
    "    reg = l2(1e-4)\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Lambda(lambda z: z)(inputs)\n",
    "    \n",
    "    # Graph Convolutional Block\n",
    "    x = GraphConvLayer(32)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    # Temporal Convolutional Network\n",
    "    res = Conv1D(32, 1, padding='causal')(x)\n",
    "    res = BatchNormalization()(res)\n",
    "    x = Conv1D(32, 5, padding='causal', activation='relu', dilation_rate=1, kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(32, 5, padding='causal', activation='relu', dilation_rate=2, kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    res = MaxPooling1D(2)(res)\n",
    "    x = Add()([x, res])\n",
    "    x = LayerNormalization()(x)\n",
    "    \n",
    "    # Adaptive Attention\n",
    "    se = GlobalAveragePooling1D()(x)\n",
    "    se = Dense(32, activation='relu', kernel_regularizer=reg)(se)\n",
    "    se = Dense(32, activation='sigmoid', kernel_regularizer=reg)(se)\n",
    "    se = Lambda(lambda z: tf.expand_dims(z, 1))(se)\n",
    "    x = Multiply()([x, se])\n",
    "    attn = MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "    x = Add()([x, attn])\n",
    "    x = LayerNormalization()(x)\n",
    "    \n",
    "    # Classification Head\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='relu', kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    if backbone:\n",
    "        for i, layer in enumerate(model.layers):\n",
    "            if i < len(backbone.layers):\n",
    "                layer.set_weights(backbone.layers[i].get_weights())\n",
    "                layer.trainable = False\n",
    "    return model\n",
    "\n",
    "# --- Meta-Adaptive Fine-Tuning ---\n",
    "\n",
    "def meta_adaptive_fine_tuning(X, y, backbone, patient_type, fold_idx):\n",
    "    model = build_neurowavesleep((X.shape[1], X.shape[2]), backbone)\n",
    "    skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "    fold_metrics = {\n",
    "        'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': [],\n",
    "        'kappa': [], 'classification_reports': [], 'confusion_matrices': []\n",
    "    }\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        if fold != fold_idx:\n",
    "            continue\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        X_train = X_train[..., np.newaxis]\n",
    "        X_test = X_test[..., np.newaxis]\n",
    "        y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "        y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=NUM_CLASSES)\n",
    "        \n",
    "        # Meta-learning simulation\n",
    "        support_idx = np.random.choice(len(X_train), len(X_train)//2)\n",
    "        X_support, y_support = X_train[support_idx], y_train_cat[support_idx]\n",
    "        model.compile(optimizer=Adam(1e-4), loss=dynamic_imbalanced_loss(gamma=1.5, beta=0.9), metrics=['accuracy'])\n",
    "        model.fit(X_support, y_support, epochs=1, batch_size=64, verbose=0)\n",
    "        \n",
    "        # Fine-tuning\n",
    "        callbacks = [\n",
    "            EarlyStopping(patience=10, restore_best_weights=True),\n",
    "            ModelCheckpoint(f\"best_neurowavesleep_{patient_type}_fold_{fold+1}.keras\", save_best_only=True),\n",
    "            ReduceLROnPlateau(patience=3, factor=0.5)\n",
    "        ]\n",
    "        history = model.fit(X_train, y_train_cat, validation_data=(X_test, y_test_cat),\n",
    "                            epochs=100, batch_size=64, callbacks=callbacks, verbose=1)\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_cls = np.argmax(y_pred, axis=1)\n",
    "        y_true_cls = np.argmax(y_test_cat, axis=1)\n",
    "        fold_metrics['accuracy'].append(history.history['accuracy'])\n",
    "        fold_metrics['val_accuracy'].append(history.history['val_accuracy'])\n",
    "        fold_metrics['loss'].append(history.history['loss'])\n",
    "        fold_metrics['val_loss'].append(history.history['val_loss'])\n",
    "        fold_metrics['kappa'].append(cohen_kappa_score(y_true_cls, y_pred_cls))\n",
    "        fold_metrics['classification_reports'].append(classification_report(y_true_cls, y_pred_cls, output_dict=True))\n",
    "        fold_metrics['confusion_matrices'].append(confusion_matrix(y_true_cls, y_pred_cls))\n",
    "        \n",
    "        print(f\"\\nFold {fold+1} Classification Report:\")\n",
    "        print(classification_report(y_true_cls, y_pred_cls))\n",
    "        print(f\"Fold {fold+1} Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_true_cls, y_pred_cls))\n",
    "        print(f\"Fold {fold+1} Cohen Kappa Score: {fold_metrics['kappa'][-1]:.4f}\")\n",
    "    \n",
    "    return model, fold_metrics\n",
    "\n",
    "# --- Main Pipeline ---\n",
    "\n",
    "patient_types = ['normal', 'apnea', 'plm', 'insomnia']\n",
    "data_paths = {\n",
    "    'normal': r\"D:\\abhishek_extracted\\normal\",\n",
    "    'apnea': r\"D:\\abhishek_extracted\\apnea\",\n",
    "    'plm': r\"D:\\abhishek_extracted\\plm\",\n",
    "    'insomnia': r\"D:\\abhishek_extracted\\insomnia\"\n",
    "}\n",
    "results = {}\n",
    "start_time = time.time()\n",
    "\n",
    "# Load and preprocess data\n",
    "datasets = {}\n",
    "for ptype in patient_types:\n",
    "    mat_files = sorted(glob.glob(os.path.join(data_paths[ptype], \"*.mat\")))[:39]\n",
    "    X_epochs_list = []\n",
    "    y_epochs_list = []\n",
    "    mask_list = []\n",
    "    for file in mat_files:\n",
    "        mat = scipy.io.loadmat(file)\n",
    "        raw_signal = mat['ppg_signals'].flatten()\n",
    "        sleep_labels = mat['sleep_stages'].flatten()\n",
    "        epochs, mask = preprocess_ppg_signal(raw_signal)\n",
    "        if len(sleep_labels) > epochs.shape[0]:\n",
    "            sleep_labels = sleep_labels[:epochs.shape[0]]\n",
    "        elif len(sleep_labels) < epochs.shape[0]:\n",
    "            pad_len = epochs.shape[0] - len(sleep_labels)\n",
    "            sleep_labels = np.pad(sleep_labels, (0, pad_len), constant_values=-1)\n",
    "        X_epochs_list.append(epochs)\n",
    "        y_epochs_list.append(sleep_labels)\n",
    "        mask_list.append(mask)\n",
    "    X_all = np.vstack(X_epochs_list)\n",
    "    y_all = np.concatenate(y_epochs_list)\n",
    "    mask_all = np.concatenate(mask_list)\n",
    "    valid_idx = (y_all != -1) & (mask_all == 1)\n",
    "    datasets[ptype] = {'X': X_all[valid_idx], 'y': y_all[valid_idx]}\n",
    "    print(f\"{ptype.capitalize()} - Total epochs: {X_all.shape[0]}, Valid epochs: {len(datasets[ptype]['y'])}\")\n",
    "\n",
    "# Contrastive pretraining\n",
    "X_combined = np.vstack([datasets[ptype]['X'] for ptype in patient_types])\n",
    "backbone = pretrain_contrastive(X_combined)\n",
    "\n",
    "# Train for each patient type\n",
    "normal_weights = None\n",
    "for ptype in patient_types:\n",
    "    print(f\"\\n=== Training for {ptype.capitalize()} Dataset ===\")\n",
    "    X_all, y_all = datasets[ptype]['X'], datasets[ptype]['y']\n",
    "    y_all_cat = tf.keras.utils.to_categorical(y_all, num_classes=NUM_CLASSES)\n",
    "    \n",
    "    # Augmentation\n",
    "    X_aug, y_aug = adversarial_frequency_mixup(X_all, y_all_cat)\n",
    "    X_aug = np.array([x / np.max(np.abs(x), axis=(0,1), keepdims=True) for x in X_aug])\n",
    "    \n",
    "    # Standardization\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_aug.reshape(-1, X_aug.shape[-1])).reshape(X_aug.shape)\n",
    "    \n",
    "    # SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_res, y_res = smote.fit_resample(X_scaled.reshape(-1, X_scaled.shape[1]*X_scaled.shape[2]),\n",
    "                                      np.argmax(y_aug, axis=1))\n",
    "    X_res = X_res.reshape(-1, X_scaled.shape[1], X_scaled.shape[2])\n",
    "    \n",
    "    # K-Fold Cross-Validation\n",
    "    fold_metrics = {\n",
    "        'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': [],\n",
    "        'kappa': [], 'classification_reports': [], 'confusion_matrices': []\n",
    "    }\n",
    "    \n",
    "    for fold in range(K_FOLDS):\n",
    "        model, metrics = meta_adaptive_fine_tuning(X_res, y_res, backbone, ptype, fold)\n",
    "        if ptype == 'normal':\n",
    "            normal_weights = model.get_weights()\n",
    "        elif normal_weights:\n",
    "            model.set_weights(normal_weights)\n",
    "        for key in fold_metrics:\n",
    "            fold_metrics[key].extend(metrics[key])\n",
    "    \n",
    "    # Aggregate metrics\n",
    "    mean_val_accuracy = np.mean([max(fold_metrics['val_accuracy'][i]) for i in range(K_FOLDS)])\n",
    "    mean_kappa = np.mean(fold_metrics['kappa'])\n",
    "    results[ptype] = {\n",
    "        'mean_val_accuracy': mean_val_accuracy,\n",
    "        'mean_kappa': mean_kappa,\n",
    "        'fold_metrics': fold_metrics\n",
    "    }\n",
    "    \n",
    "    # Interpretability\n",
    "    explainer = shap.DeepExplainer(model, X_res[:100])\n",
    "    shap_values = explainer.shap_values(X_res[:100])\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.heatmap(np.mean(np.abs(shap_values[0]), axis=0), cmap='viridis')\n",
    "    plt.title(f\"{ptype.capitalize()} SHAP Feature Importance\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    for fold in range(K_FOLDS):\n",
    "        plt.plot(fold_metrics['accuracy'][fold], label=f'train fold {fold+1}')\n",
    "        plt.plot(fold_metrics['val_accuracy'][fold], label=f'val fold {fold+1}')\n",
    "    plt.title(f\"{ptype.capitalize()} Accuracy Across Folds\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    for fold in range(K_FOLDS):\n",
    "        plt.plot(fold_metrics['loss'][fold], label=f'train fold {fold+1}')\n",
    "        plt.plot(fold_metrics['val_loss'][fold], label=f'val fold {fold+1}')\n",
    "    plt.title(f\"{ptype.capitalize()} Loss Across Folds\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save and export\n",
    "    model.save(f\"neurowavesleep_{ptype}_model.keras\")\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    with open(f\"neurowavesleep_{ptype}_model.tflite\", \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "# --- Final Summary ---\n",
    "print(\"\\n=== Final Summary Across Patient Types ===\")\n",
    "for ptype in patient_types:\n",
    "    print(f\"{ptype.capitalize()}:\")\n",
    "    print(f\"  Mean Validation Accuracy: {results[ptype]['mean_val_accuracy']:.4f}\")\n",
    "    print(f\"  Mean Cohen Kappa Score: {results[ptype]['mean_kappa']:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\n⏱️ Total training time: {(end_time - start_time)/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fafdc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce5ce8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU detected: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DST\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 7680, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " gaussian_noise (GaussianNoise)  (None, 7680, 1)     0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " separable_conv1d (SeparableCon  (None, 7680, 64)    143         ['gaussian_noise[0][0]']         \n",
      " v1D)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 7680, 64)    256         ['separable_conv1d[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " spatial_dropout1d (SpatialDrop  (None, 7680, 64)    0           ['batch_normalization[0][0]']    \n",
      " out1D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 3840, 64)     0           ['spatial_dropout1d[0][0]']      \n",
      "                                                                                                  \n",
      " separable_conv1d_1 (SeparableC  (None, 3840, 64)    4352        ['max_pooling1d[0][0]']          \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " separable_conv1d_2 (SeparableC  (None, 3840, 64)    4480        ['max_pooling1d[0][0]']          \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " separable_conv1d_3 (SeparableC  (None, 3840, 64)    4608        ['max_pooling1d[0][0]']          \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 3840, 64)    256         ['separable_conv1d_1[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 3840, 64)    256         ['separable_conv1d_2[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 3840, 64)    256         ['separable_conv1d_3[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3840, 192)    0           ['batch_normalization_1[0][0]',  \n",
      "                                                                  'batch_normalization_2[0][0]',  \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 192)         0           ['concatenate[0][0]']            \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           12352       ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64)          256         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 192)          12480       ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1, 192)       0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " separable_conv1d_4 (SeparableC  (None, 3840, 192)   12544       ['max_pooling1d[0][0]']          \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 3840, 192)    0           ['concatenate[0][0]',            \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 3840, 192)   768         ['separable_conv1d_4[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 3840, 192)    0           ['multiply[0][0]',               \n",
      "                                                                  'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 3840, 192)   384         ['add[0][0]']                    \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " separable_conv1d_6 (SeparableC  (None, 3840, 64)    13696       ['layer_normalization[0][0]']    \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 3840, 64)    256         ['separable_conv1d_6[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout1d_1 (SpatialDr  (None, 3840, 64)    0           ['batch_normalization_7[0][0]']  \n",
      " opout1D)                                                                                         \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 1920, 64)    0           ['spatial_dropout1d_1[0][0]']    \n",
      "                                                                                                  \n",
      " separable_conv1d_8 (SeparableC  (None, 1920, 64)    4608        ['max_pooling1d_1[0][0]']        \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " average_pooling1d (AveragePool  (None, 1920, 64)    0           ['max_pooling1d_1[0][0]']        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ing1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 1920, 64)    256         ['separable_conv1d_8[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 1920, 64)     0           ['max_pooling1d_1[0][0]',        \n",
      "                                                                  'average_pooling1d[0][0]']      \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 1920, 64)     0           ['batch_normalization_9[0][0]',  \n",
      "                                                                  'tf.math.subtract[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 1920, 64)    128         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " separable_conv1d_9 (SeparableC  (None, 1920, 128)   8640        ['layer_normalization_1[0][0]']  \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 1920, 128)   512         ['separable_conv1d_9[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " spatial_dropout1d_2 (SpatialDr  (None, 1920, 128)   0           ['batch_normalization_10[0][0]'] \n",
      " opout1D)                                                                                         \n",
      "                                                                                                  \n",
      " separable_conv1d_5 (SeparableC  (None, 3840, 32)    6368        ['layer_normalization[0][0]']    \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 960, 128)    0           ['spatial_dropout1d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 3840, 32)    128         ['separable_conv1d_5[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 128)         0           ['max_pooling1d_3[0][0]']        \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " separable_conv1d_7 (SeparableC  (None, 3840, 64)    2144        ['batch_normalization_6[0][0]']  \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256)          33024       ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 3840, 64)    256         ['separable_conv1d_7[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 256)         1024        ['dense_2[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 1920, 64)    0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          32896       ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv1d_10 (Separable  (None, 1920, 128)   8384        ['max_pooling1d_2[0][0]']        \n",
      " Conv1D)                                                                                          \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 1, 128)       0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 1920, 128)   512         ['separable_conv1d_10[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 960, 128)     0           ['max_pooling1d_3[0][0]',        \n",
      "                                                                  'lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 960, 128)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 960, 128)     0           ['multiply_1[0][0]',             \n",
      "                                                                  'max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 960, 128)    256         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 122880)       0           ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          15728768    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 128)         512         ['dense_4[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           8256        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 64)          256         ['dense_5[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_6 (Dense)                (None, 5)            325         ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,904,596\n",
      "Trainable params: 15,901,716\n",
      "Non-trainable params: 2,880\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1479/1479 [==============================] - 468s 313ms/step - loss: 0.5121 - accuracy: 0.3352 - val_loss: 0.4214 - val_accuracy: 0.4560 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "1479/1479 [==============================] - 461s 312ms/step - loss: 0.4083 - accuracy: 0.4263 - val_loss: 0.3796 - val_accuracy: 0.4770 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "1479/1479 [==============================] - 460s 311ms/step - loss: 0.3707 - accuracy: 0.4679 - val_loss: 0.3545 - val_accuracy: 0.4952 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "1479/1479 [==============================] - 460s 311ms/step - loss: 0.3475 - accuracy: 0.5036 - val_loss: 0.3403 - val_accuracy: 0.5682 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "1479/1479 [==============================] - 461s 312ms/step - loss: 0.3302 - accuracy: 0.5396 - val_loss: 0.3236 - val_accuracy: 0.5956 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "1479/1479 [==============================] - 462s 312ms/step - loss: 0.3160 - accuracy: 0.5748 - val_loss: 0.3057 - val_accuracy: 0.6294 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "1479/1479 [==============================] - 464s 314ms/step - loss: 0.3052 - accuracy: 0.6032 - val_loss: 0.2991 - val_accuracy: 0.6391 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "1479/1479 [==============================] - 464s 314ms/step - loss: 0.2951 - accuracy: 0.6277 - val_loss: 0.2881 - val_accuracy: 0.6597 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "1479/1479 [==============================] - 463s 313ms/step - loss: 0.2883 - accuracy: 0.6460 - val_loss: 0.2929 - val_accuracy: 0.6566 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "1479/1479 [==============================] - 465s 314ms/step - loss: 0.2822 - accuracy: 0.6603 - val_loss: 0.2902 - val_accuracy: 0.6669 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "1479/1479 [==============================] - 464s 314ms/step - loss: 0.2773 - accuracy: 0.6739 - val_loss: 0.2755 - val_accuracy: 0.6936 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "1479/1479 [==============================] - 462s 313ms/step - loss: 0.2718 - accuracy: 0.6879 - val_loss: 0.3035 - val_accuracy: 0.6592 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "1479/1479 [==============================] - 463s 313ms/step - loss: 0.2682 - accuracy: 0.6979 - val_loss: 0.2661 - val_accuracy: 0.7068 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "1479/1479 [==============================] - 464s 314ms/step - loss: 0.2646 - accuracy: 0.7070 - val_loss: 0.2657 - val_accuracy: 0.7137 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "1479/1479 [==============================] - 464s 314ms/step - loss: 0.2627 - accuracy: 0.7160 - val_loss: 0.2740 - val_accuracy: 0.6964 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "1479/1479 [==============================] - 463s 313ms/step - loss: 0.2599 - accuracy: 0.7227 - val_loss: 0.2728 - val_accuracy: 0.6943 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "1479/1479 [==============================] - 465s 314ms/step - loss: 0.2579 - accuracy: 0.7297 - val_loss: 0.2732 - val_accuracy: 0.7040 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "1479/1479 [==============================] - 466s 315ms/step - loss: 0.2402 - accuracy: 0.7552 - val_loss: 0.2451 - val_accuracy: 0.7506 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "1479/1479 [==============================] - 465s 315ms/step - loss: 0.2292 - accuracy: 0.7646 - val_loss: 0.2400 - val_accuracy: 0.7472 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "1479/1479 [==============================] - 465s 315ms/step - loss: 0.2199 - accuracy: 0.7757 - val_loss: 0.2345 - val_accuracy: 0.7581 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "1479/1479 [==============================] - 464s 314ms/step - loss: 0.2140 - accuracy: 0.7837 - val_loss: 0.2355 - val_accuracy: 0.7487 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "1479/1479 [==============================] - 464s 314ms/step - loss: 0.2097 - accuracy: 0.7860 - val_loss: 0.2273 - val_accuracy: 0.7573 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "1479/1479 [==============================] - 463s 313ms/step - loss: 0.2045 - accuracy: 0.7944 - val_loss: 0.2281 - val_accuracy: 0.7590 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "1479/1479 [==============================] - 464s 314ms/step - loss: 0.2016 - accuracy: 0.7961 - val_loss: 0.2266 - val_accuracy: 0.7665 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "1479/1479 [==============================] - 464s 314ms/step - loss: 0.1979 - accuracy: 0.8012 - val_loss: 0.2264 - val_accuracy: 0.7688 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "1479/1479 [==============================] - 465s 314ms/step - loss: 0.1965 - accuracy: 0.8038 - val_loss: 0.2195 - val_accuracy: 0.7816 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "1479/1479 [==============================] - 464s 314ms/step - loss: 0.1928 - accuracy: 0.8069 - val_loss: 0.2221 - val_accuracy: 0.7781 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "1479/1479 [==============================] - 466s 315ms/step - loss: 0.1909 - accuracy: 0.8121 - val_loss: 0.2204 - val_accuracy: 0.7775 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "1479/1479 [==============================] - 477s 323ms/step - loss: 0.1896 - accuracy: 0.8125 - val_loss: 0.2229 - val_accuracy: 0.7798 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "1479/1479 [==============================] - 479s 324ms/step - loss: 0.1808 - accuracy: 0.8270 - val_loss: 0.2190 - val_accuracy: 0.7819 - lr: 2.5000e-05\n",
      "Epoch 31/100\n",
      "1479/1479 [==============================] - 467s 316ms/step - loss: 0.1747 - accuracy: 0.8344 - val_loss: 0.2144 - val_accuracy: 0.7899 - lr: 2.5000e-05\n",
      "Epoch 32/100\n",
      "1479/1479 [==============================] - 467s 316ms/step - loss: 0.1716 - accuracy: 0.8366 - val_loss: 0.2134 - val_accuracy: 0.7920 - lr: 2.5000e-05\n",
      "Epoch 33/100\n",
      "1479/1479 [==============================] - 469s 317ms/step - loss: 0.1677 - accuracy: 0.8413 - val_loss: 0.2082 - val_accuracy: 0.7995 - lr: 2.5000e-05\n",
      "Epoch 34/100\n",
      "1479/1479 [==============================] - 466s 315ms/step - loss: 0.1642 - accuracy: 0.8458 - val_loss: 0.2196 - val_accuracy: 0.7758 - lr: 2.5000e-05\n",
      "Epoch 35/100\n",
      "1479/1479 [==============================] - 467s 316ms/step - loss: 0.1613 - accuracy: 0.8479 - val_loss: 0.2125 - val_accuracy: 0.7880 - lr: 2.5000e-05\n",
      "Epoch 36/100\n",
      "1479/1479 [==============================] - 468s 316ms/step - loss: 0.1587 - accuracy: 0.8517 - val_loss: 0.2106 - val_accuracy: 0.8012 - lr: 2.5000e-05\n",
      "Epoch 37/100\n",
      "1479/1479 [==============================] - 466s 315ms/step - loss: 0.1539 - accuracy: 0.8578 - val_loss: 0.2098 - val_accuracy: 0.7934 - lr: 1.2500e-05\n",
      "Epoch 38/100\n",
      "1479/1479 [==============================] - 466s 315ms/step - loss: 0.1521 - accuracy: 0.8617 - val_loss: 0.2101 - val_accuracy: 0.7961 - lr: 1.2500e-05\n",
      "Epoch 39/100\n",
      "1479/1479 [==============================] - 468s 316ms/step - loss: 0.1494 - accuracy: 0.8646 - val_loss: 0.2043 - val_accuracy: 0.8029 - lr: 1.2500e-05\n",
      "Epoch 40/100\n",
      "1479/1479 [==============================] - 466s 315ms/step - loss: 0.1469 - accuracy: 0.8666 - val_loss: 0.2077 - val_accuracy: 0.7997 - lr: 1.2500e-05\n",
      "Epoch 41/100\n",
      "1479/1479 [==============================] - 465s 315ms/step - loss: 0.1440 - accuracy: 0.8697 - val_loss: 0.2008 - val_accuracy: 0.8104 - lr: 1.2500e-05\n",
      "Epoch 42/100\n",
      "1479/1479 [==============================] - 466s 315ms/step - loss: 0.1442 - accuracy: 0.8690 - val_loss: 0.2048 - val_accuracy: 0.8051 - lr: 1.2500e-05\n",
      "Epoch 43/100\n",
      "1479/1479 [==============================] - 464s 314ms/step - loss: 0.1428 - accuracy: 0.8691 - val_loss: 0.2035 - val_accuracy: 0.8075 - lr: 1.2500e-05\n",
      "Epoch 44/100\n",
      "1479/1479 [==============================] - 461s 312ms/step - loss: 0.1407 - accuracy: 0.8732 - val_loss: 0.2041 - val_accuracy: 0.8060 - lr: 1.2500e-05\n",
      "Epoch 45/100\n",
      "1479/1479 [==============================] - 459s 311ms/step - loss: 0.1382 - accuracy: 0.8753 - val_loss: 0.2018 - val_accuracy: 0.8074 - lr: 6.2500e-06\n",
      "Epoch 46/100\n",
      "1479/1479 [==============================] - 459s 310ms/step - loss: 0.1367 - accuracy: 0.8771 - val_loss: 0.2040 - val_accuracy: 0.8074 - lr: 6.2500e-06\n",
      "Epoch 47/100\n",
      "1479/1479 [==============================] - 459s 310ms/step - loss: 0.1359 - accuracy: 0.8780 - val_loss: 0.2030 - val_accuracy: 0.8087 - lr: 6.2500e-06\n",
      "Epoch 48/100\n",
      "1479/1479 [==============================] - 456s 309ms/step - loss: 0.1336 - accuracy: 0.8805 - val_loss: 0.2028 - val_accuracy: 0.8118 - lr: 3.1250e-06\n",
      "Epoch 49/100\n",
      "1479/1479 [==============================] - 457s 309ms/step - loss: 0.1335 - accuracy: 0.8814 - val_loss: 0.2038 - val_accuracy: 0.8076 - lr: 3.1250e-06\n",
      "Epoch 50/100\n",
      "1479/1479 [==============================] - 457s 309ms/step - loss: 0.1334 - accuracy: 0.8817 - val_loss: 0.2044 - val_accuracy: 0.8065 - lr: 3.1250e-06\n",
      "Epoch 51/100\n",
      "1479/1479 [==============================] - 457s 309ms/step - loss: 0.1328 - accuracy: 0.8817 - val_loss: 0.2035 - val_accuracy: 0.8075 - lr: 1.5625e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740/740 [==============================] - 31s 42ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69      4731\n",
      "           1       0.97      0.94      0.95      4730\n",
      "           2       0.62      0.71      0.66      4731\n",
      "           3       0.98      0.95      0.96      4731\n",
      "           4       0.86      0.74      0.80      4731\n",
      "\n",
      "    accuracy                           0.81     23654\n",
      "   macro avg       0.82      0.81      0.81     23654\n",
      "weighted avg       0.82      0.81      0.81     23654\n",
      "\n",
      "[[3344   39 1142   10  196]\n",
      " [ 118 4438   76   76   22]\n",
      " [ 992   19 3367   22  331]\n",
      " [  59   76   69 4501   26]\n",
      " [ 393   12  804    2 3520]]\n",
      "\n",
      "🧠 Cohen Kappa Score: 0.7630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 11). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DST\\AppData\\Local\\Temp\\tmplpjoefl3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DST\\AppData\\Local\\Temp\\tmplpjoefl3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ Total training time: 396.35 minutes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, glob, scipy.io, time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, SeparableConv1D, MaxPooling1D, GlobalAveragePooling1D, AveragePooling1D,\n",
    "                                     Flatten, Dense, Dropout, Multiply, Add, LayerNormalization,\n",
    "                                     Lambda, GaussianNoise)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# ✅ Ensure GPU Usage\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"✅ GPU detected: {gpus[0]}\")\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "else:\n",
    "    print(\"⚠️ No GPU found. Training might be slow.\")\n",
    "\n",
    "# ⏱️ Start Timing\n",
    "start_time = time.time()\n",
    "\n",
    "# 📂 Load PPG Data\n",
    "folder_path = r\"D:\\abhishek_extracted\\insomnia\"\n",
    "mat_files = sorted(glob.glob(os.path.join(folder_path, \"*.mat\")))[:50]\n",
    "\n",
    "X_list, y_list = [], []\n",
    "for file in mat_files:\n",
    "    mat = scipy.io.loadmat(file)\n",
    "    X_list.append(mat['ppg_signals'])\n",
    "    y_list.append(mat['sleep_stages'].flatten())\n",
    "\n",
    "X = np.vstack(X_list)\n",
    "y = np.concatenate(y_list)\n",
    "\n",
    "# ✅ Data Augmentation Functions\n",
    "def jitter(x, sigma=0.01):\n",
    "    return x + np.random.normal(loc=0, scale=sigma, size=x.shape)\n",
    "\n",
    "def scaling(x, sigma=0.1):\n",
    "    return x * np.random.normal(loc=1.0, scale=sigma, size=x.shape)\n",
    "\n",
    "def magnitude_warp(x, sigma=0.2):\n",
    "    x = x.reshape(-1)\n",
    "    warp = np.sin(np.linspace(0, np.pi, len(x))) * np.random.normal(1, sigma)\n",
    "    return x * warp\n",
    "\n",
    "# 🔁 Class-wise Augmentation (focus on underrepresented)\n",
    "np.random.seed(42)\n",
    "augmented = []\n",
    "target_distribution = np.bincount(y)\n",
    "minority_classes = np.where(target_distribution < np.median(target_distribution))[0]\n",
    "\n",
    "for signal, label in zip(X, y):\n",
    "    if label in minority_classes:\n",
    "        if np.random.rand() < 0.5:\n",
    "            signal = jitter(signal)\n",
    "        if np.random.rand() < 0.5:\n",
    "            signal = magnitude_warp(signal)\n",
    "        if np.random.rand() < 0.5:\n",
    "            signal = scaling(signal.reshape(1, -1)).flatten()\n",
    "    augmented.append(signal)\n",
    "\n",
    "X = np.array(augmented)\n",
    "\n",
    "# 🔄 Standardization\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 🧩 Handle Class Imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# 🧠 Class Weights\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_res), y=y_res)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# 🔁 Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, y_res, test_size=0.2, stratify=y_res, random_state=42\n",
    ")\n",
    "\n",
    "# 🔷 Preprocessing\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=5)\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=5)\n",
    "\n",
    "# ⚠️ Focal Loss Function\n",
    "def focal_loss(gamma=1.5, alpha=[0.7, 0.5, 0.5, 0.3, 0.3]):\n",
    "    alpha = tf.constant(alpha, dtype=tf.float32)\n",
    "\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        \n",
    "        # Calculate cross-entropy\n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        \n",
    "        # Pick alpha for each class (broadcasted)\n",
    "        alpha_factor = y_true * alpha\n",
    "\n",
    "        # Modulating factor\n",
    "        modulating_factor = tf.math.pow(1.0 - y_pred, gamma)\n",
    "\n",
    "        loss = alpha_factor * modulating_factor * ce\n",
    "        return tf.reduce_mean(tf.reduce_sum(loss, axis=1))  # Sum across classes\n",
    "    return loss_fn\n",
    "\n",
    "\n",
    "# 🔹 MSR-SE Block: Multi-Scale Residual Squeeze-and-Excite\n",
    "def MSR_SE_Block(x, filters):\n",
    "    reg = tf.keras.regularizers.l2(1e-4)\n",
    "\n",
    "    branch1 = SeparableConv1D(filters, 3, padding='same', activation='relu', kernel_regularizer=reg)(x)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    branch2 = SeparableConv1D(filters, 5, padding='same', activation='relu', kernel_regularizer=reg)(x)\n",
    "    branch2 = BatchNormalization()(branch2)\n",
    "    branch3 = SeparableConv1D(filters, 7, padding='same', activation='relu', kernel_regularizer=reg)(x)\n",
    "    branch3 = BatchNormalization()(branch3)\n",
    "\n",
    "    concat = Concatenate()([branch1, branch2, branch3])\n",
    "    squeeze = GlobalAveragePooling1D()(concat)\n",
    "\n",
    "    excitation = Dense(filters, activation='relu', kernel_regularizer=reg)(squeeze)\n",
    "    excitation = BatchNormalization()(excitation)\n",
    "    excitation = Dense(concat.shape[-1], activation='sigmoid', kernel_regularizer=reg)(excitation)\n",
    "    excitation = Lambda(lambda s: tf.expand_dims(s, 1))(excitation)\n",
    "\n",
    "    scaled = Multiply()([concat, excitation])\n",
    "    residual = SeparableConv1D(concat.shape[-1], 1, padding='same', kernel_regularizer=reg)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    out = Add()([scaled, residual])\n",
    "    return LayerNormalization()(out)\n",
    "\n",
    "\n",
    "# 🔹 Frequency Fusion Block\n",
    "def FrequencyFusionBlock(x, filters):\n",
    "    reg = tf.keras.regularizers.l2(1e-4)\n",
    "\n",
    "    # Low-frequency emphasis (smooth features)\n",
    "    low = SeparableConv1D(filters, 7, padding='same', activation='relu', kernel_regularizer=reg)(x)\n",
    "    low = BatchNormalization()(low)\n",
    "\n",
    "    # High-frequency component\n",
    "    high = x - AveragePooling1D(pool_size=3, strides=1, padding='same')(x)\n",
    "\n",
    "    out = Add()([low, high])\n",
    "    return LayerNormalization()(out)\n",
    "\n",
    "\n",
    "def build_hybrid_cnn_rvfl(input_shape):\n",
    "    reg = l2(1e-4)\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = GaussianNoise(0.05)(inputs)\n",
    "\n",
    "    # First CNN Block\n",
    "    x = SeparableConv1D(64, 15, padding='same', activation='relu', kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # 🔹 MSR-SE Block\n",
    "    x = MSR_SE_Block(x, 64)\n",
    "\n",
    "    # Second Conv Block + Residual\n",
    "    res = SeparableConv1D(32, 1, padding='same', kernel_regularizer=reg)(x)\n",
    "    res = BatchNormalization()(res)\n",
    "\n",
    "    x = SeparableConv1D(64, 7, padding='same', activation='relu', kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    res = SeparableConv1D(64, 1, padding='same', kernel_regularizer=reg)(res)\n",
    "    res = BatchNormalization()(res)\n",
    "    res = MaxPooling1D(2)(res)\n",
    "\n",
    "    # 🔹 Frequency Fusion Block\n",
    "    x = FrequencyFusionBlock(x, 64)\n",
    "\n",
    "    # Third Conv Block\n",
    "    x = SeparableConv1D(128, 5, padding='same', activation='relu', kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    res = SeparableConv1D(128, 1, padding='same', kernel_regularizer=reg)(res)\n",
    "    res = BatchNormalization()(res)\n",
    "    res = MaxPooling1D(2)(res)\n",
    "\n",
    "    # Attention Mechanism\n",
    "    attn = GlobalAveragePooling1D()(x)\n",
    "    attn = Dense(256, activation=\"relu\", kernel_regularizer=reg)(attn)\n",
    "    attn = BatchNormalization()(attn)\n",
    "    attn = Dense(128, activation=\"sigmoid\", kernel_regularizer=reg)(attn)\n",
    "    attn = Lambda(lambda z: tf.expand_dims(z, 1))(attn)\n",
    "    x = Multiply()([x, attn])\n",
    "\n",
    "    # Residual Merge\n",
    "    x = Add()([x, res])\n",
    "    x = LayerNormalization()(x)\n",
    "\n",
    "    # RVFL-like Dense Layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    outputs = Dense(5, activation='softmax')(x)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# ⚙️ Compile & Train\n",
    "model = build_hybrid_cnn_rvfl((X_train.shape[1], 1))\n",
    "model.compile(optimizer=Adam(1e-4), loss=focal_loss(gamma=1.5, alpha=[0.7, 0.5, 0.5, 0.3, 0.3]), metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"best_model.keras\", save_best_only=True),\n",
    "    ReduceLROnPlateau(patience=3, factor=0.5)\n",
    "]\n",
    "\n",
    "history = model.fit(X_train, y_train_cat, validation_data=(X_test, y_test_cat),\n",
    "                    epochs=100, batch_size=64, class_weight=class_weight_dict,\n",
    "                    callbacks=callbacks, verbose=1)\n",
    "\n",
    "# 📉 Training Curves\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 📊 Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_cls = np.argmax(y_pred, axis=1)\n",
    "y_true_cls = np.argmax(y_test_cat, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_cls, y_pred_cls))\n",
    "\n",
    "cm = confusion_matrix(y_true_cls, y_pred_cls)\n",
    "print(cm)\n",
    "\n",
    "kappa = cohen_kappa_score(y_true_cls, y_pred_cls)\n",
    "print(f\"\\n🧠 Cohen Kappa Score: {kappa:.4f}\")\n",
    "\n",
    "# 💾 Save for Deployment\n",
    "model.save(\"cnn_rvfl_final_model.keras\")\n",
    "\n",
    "# ✅ Export for TFLite (Edge Devices)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open(\"cnn_rvfl_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# ⏱️ Total Training Time\n",
    "end_time = time.time()\n",
    "print(f\"\\n⏱️ Total training time: {(end_time - start_time)/60:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248201c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c179f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU detected: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DST\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Inputs have incompatible shapes. Received shapes (960, 64) and (960, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 237\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Model(inputs, outputs)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# ⚙️ Compile & Train\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_hybrid_cnn_rvfl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(\u001b[38;5;241m1e-4\u001b[39m), loss\u001b[38;5;241m=\u001b[39mfocal_loss(gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.3\u001b[39m]), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    240\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[1;32mIn[7], line 222\u001b[0m, in \u001b[0;36mbuild_hybrid_cnn_rvfl\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m    218\u001b[0m x \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.3\u001b[39m)(x)  \u001b[38;5;66;03m# After attention multiplication and before residual Add\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# Residual Merge\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mAdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m x \u001b[38;5;241m=\u001b[39m LayerNormalization()(x)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# RVFL-like Dense Layers\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\merging\\base_merge.py:74\u001b[0m, in \u001b[0;36m_Merge._compute_elemwise_op_output_shape\u001b[1;34m(self, shape1, shape2)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[1;32m---> 74\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     75\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs have incompatible shapes. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         output_shape\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(output_shape)\n",
      "\u001b[1;31mValueError\u001b[0m: Inputs have incompatible shapes. Received shapes (960, 64) and (960, 128)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, glob, scipy.io, time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, SeparableConv1D, MaxPooling1D, GlobalAveragePooling1D, AveragePooling1D,\n",
    "                                     Flatten, Dense, Dropout, Multiply, Add, LayerNormalization,\n",
    "                                     Lambda, GaussianNoise)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# ✅ Ensure GPU Usage\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"✅ GPU detected: {gpus[0]}\")\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "else:\n",
    "    print(\"⚠️ No GPU found. Training might be slow.\")\n",
    "\n",
    "# ⏱️ Start Timing\n",
    "start_time = time.time()\n",
    "\n",
    "# 📂 Load PPG Data\n",
    "folder_path = r\"D:\\abhishek_extracted\\insomnia\"\n",
    "mat_files = sorted(glob.glob(os.path.join(folder_path, \"*.mat\")))[:50]\n",
    "\n",
    "X_list, y_list = [], []\n",
    "for file in mat_files:\n",
    "    mat = scipy.io.loadmat(file)\n",
    "    X_list.append(mat['ppg_signals'])\n",
    "    y_list.append(mat['sleep_stages'].flatten())\n",
    "\n",
    "X = np.vstack(X_list)\n",
    "y = np.concatenate(y_list)\n",
    "\n",
    "# ✅ Data Augmentation Functions\n",
    "def jitter(x, sigma=0.01):\n",
    "    return x + np.random.normal(loc=0, scale=sigma, size=x.shape)\n",
    "\n",
    "def scaling(x, sigma=0.1):\n",
    "    return x * np.random.normal(loc=1.0, scale=sigma, size=x.shape)\n",
    "\n",
    "def magnitude_warp(x, sigma=0.2):\n",
    "    x = x.reshape(-1)\n",
    "    warp = np.sin(np.linspace(0, np.pi, len(x))) * np.random.normal(1, sigma)\n",
    "    return x * warp\n",
    "\n",
    "# 🔁 Class-wise Augmentation (focus on underrepresented)\n",
    "np.random.seed(42)\n",
    "augmented = []\n",
    "target_distribution = np.bincount(y)\n",
    "minority_classes = np.where(target_distribution < np.median(target_distribution))[0]\n",
    "\n",
    "for signal, label in zip(X, y):\n",
    "    if label in minority_classes:\n",
    "        if np.random.rand() < 0.5:\n",
    "            signal = jitter(signal)\n",
    "        if np.random.rand() < 0.5:\n",
    "            signal = magnitude_warp(signal)\n",
    "        if np.random.rand() < 0.5:\n",
    "            signal = scaling(signal.reshape(1, -1)).flatten()\n",
    "    augmented.append(signal)\n",
    "\n",
    "X = np.array(augmented)\n",
    "\n",
    "# 🔄 Standardization\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 🧩 Handle Class Imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# 🧠 Class Weights\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_res), y=y_res)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# 🔁 Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, y_res, test_size=0.2, stratify=y_res, random_state=42\n",
    ")\n",
    "\n",
    "# 🔷 Preprocessing\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=5)\n",
    "y_train_cat = y_train_cat * (1 - 0.1) + 0.1 / 5  # 0.1 label smoothing\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=5)\n",
    "\n",
    "# ⚠️ Focal Loss Function\n",
    "def focal_loss(gamma=1.5, alpha=[0.7, 0.5, 0.5, 0.3, 0.3]):\n",
    "    alpha = tf.constant(alpha, dtype=tf.float32)\n",
    "\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        \n",
    "        # Calculate cross-entropy\n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        \n",
    "        # Pick alpha for each class (broadcasted)\n",
    "        alpha_factor = y_true * alpha\n",
    "\n",
    "        # Modulating factor\n",
    "        modulating_factor = tf.math.pow(1.0 - y_pred, gamma)\n",
    "\n",
    "        loss = alpha_factor * modulating_factor * ce\n",
    "        return tf.reduce_mean(tf.reduce_sum(loss, axis=1))  # Sum across classes\n",
    "    return loss_fn\n",
    "\n",
    "\n",
    "# 🔹 MSR-SE Block: Multi-Scale Residual Squeeze-and-Excite\n",
    "def MSR_SE_Block(x, filters):\n",
    "    reg = tf.keras.regularizers.l2(1e-4)\n",
    "\n",
    "    branch1 = SeparableConv1D(filters, 3, padding='same', activation='relu', kernel_regularizer=reg)(x)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    branch2 = SeparableConv1D(filters, 5, padding='same', activation='relu', kernel_regularizer=reg)(x)\n",
    "    branch2 = BatchNormalization()(branch2)\n",
    "    branch3 = SeparableConv1D(filters, 7, padding='same', activation='relu', kernel_regularizer=reg)(x)\n",
    "    branch3 = BatchNormalization()(branch3)\n",
    "\n",
    "    concat = Concatenate()([branch1, branch2, branch3])\n",
    "    squeeze = GlobalAveragePooling1D()(concat)\n",
    "\n",
    "    excitation = Dense(filters, activation='relu', kernel_regularizer=reg)(squeeze)\n",
    "    excitation = BatchNormalization()(excitation)\n",
    "    excitation = Dense(concat.shape[-1], activation='sigmoid', kernel_regularizer=reg)(excitation)\n",
    "    excitation = Lambda(lambda s: tf.expand_dims(s, 1))(excitation)\n",
    "\n",
    "    scaled = Multiply()([concat, excitation])\n",
    "    residual = SeparableConv1D(concat.shape[-1], 1, padding='same', kernel_regularizer=reg)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    out = Add()([scaled, residual])\n",
    "    return LayerNormalization()(out)\n",
    "\n",
    "\n",
    "# 🔹 Frequency Fusion Block\n",
    "def FrequencyFusionBlock(x, filters):\n",
    "    reg = tf.keras.regularizers.l2(1e-4)\n",
    "\n",
    "    # Low-frequency emphasis (smooth features)\n",
    "    low = SeparableConv1D(filters, 7, padding='same', activation='relu', kernel_regularizer=reg)(x)\n",
    "    low = BatchNormalization()(low)\n",
    "\n",
    "    # High-frequency component\n",
    "    high = x - AveragePooling1D(pool_size=3, strides=1, padding='same')(x)\n",
    "\n",
    "    out = Add()([low, high])\n",
    "    return LayerNormalization()(out)\n",
    "\n",
    "\n",
    "def build_hybrid_cnn_rvfl(input_shape):\n",
    "    reg = l2(1e-3)\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = GaussianNoise(0.05)(inputs)\n",
    "\n",
    "    # First CNN Block\n",
    "    x = SeparableConv1D(64, 15, padding='same', activation='relu', kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SpatialDropout1D(0.3)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # 🔹 MSR-SE Block\n",
    "    x = MSR_SE_Block(x, 64)\n",
    "\n",
    "    # Second Conv Block + Residual\n",
    "    res = SeparableConv1D(32, 1, padding='same', kernel_regularizer=reg)(x)\n",
    "    res = BatchNormalization()(res)\n",
    "\n",
    "    x = SeparableConv1D(64, 7, padding='same', activation='relu', kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SpatialDropout1D(0.3)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    res = SeparableConv1D(64, 1, padding='same', kernel_regularizer=reg)(res)\n",
    "    res = BatchNormalization()(res)\n",
    "    res = MaxPooling1D(2)(res)\n",
    "\n",
    "    # 🔹 Frequency Fusion Block\n",
    "    x = FrequencyFusionBlock(x, 64)\n",
    "\n",
    "    # Third Conv Block\n",
    "    x = SeparableConv1D(64, 5, padding='same', activation='relu', kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    res = SeparableConv1D(128, 1, padding='same', kernel_regularizer=reg)(res)\n",
    "    res = BatchNormalization()(res)\n",
    "    res = MaxPooling1D(2)(res)\n",
    "\n",
    "    # Attention Mechanism\n",
    "    attn = GlobalAveragePooling1D()(x)\n",
    "    attn = Dense(256, activation=\"relu\", kernel_regularizer=reg)(attn)\n",
    "    attn = BatchNormalization()(attn)\n",
    "    attn = Dense(x.shape[-1], activation=\"sigmoid\", kernel_regularizer=reg)(attn)\n",
    "    attn = Lambda(lambda z: tf.expand_dims(z, 1))(attn)\n",
    "    x = Multiply()([x, attn])\n",
    "\n",
    "    x = Dropout(0.3)(x)  # After attention multiplication and before residual Add\n",
    "\n",
    "\n",
    "    # Residual Merge\n",
    "    x = Add()([x, res])\n",
    "    x = LayerNormalization()(x)\n",
    "\n",
    "    # RVFL-like Dense Layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    outputs = Dense(5, activation='softmax')(x)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# ⚙️ Compile & Train\n",
    "model = build_hybrid_cnn_rvfl((X_train.shape[1], 1))\n",
    "model.compile(optimizer=Adam(1e-4), loss=focal_loss(gamma=1.5, alpha=[0.7, 0.5, 0.5, 0.3, 0.3]), metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, min_delta=1e-4, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"best_model.keras\", save_best_only=True),\n",
    "    ReduceLROnPlateau(patience=3, factor=0.5, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "history = model.fit(X_train, y_train_cat, validation_data=(X_test, y_test_cat),\n",
    "                    epochs=100, batch_size=64, class_weight=class_weight_dict,\n",
    "                    callbacks=callbacks, verbose=1)\n",
    "\n",
    "# 📉 Training Curves\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 📊 Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_cls = np.argmax(y_pred, axis=1)\n",
    "y_true_cls = np.argmax(y_test_cat, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_cls, y_pred_cls))\n",
    "\n",
    "cm = confusion_matrix(y_true_cls, y_pred_cls)\n",
    "print(cm)\n",
    "\n",
    "kappa = cohen_kappa_score(y_true_cls, y_pred_cls)\n",
    "print(f\"\\n🧠 Cohen Kappa Score: {kappa:.4f}\")\n",
    "\n",
    "# 💾 Save for Deployment\n",
    "model.save(\"cnn_rvfl_final_model.keras\")\n",
    "\n",
    "# ✅ Export for TFLite (Edge Devices)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open(\"cnn_rvfl_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# ⏱️ Total Training Time\n",
    "end_time = time.time()\n",
    "print(f\"\\n⏱️ Total training time: {(end_time - start_time)/60:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f175d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow GPU)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
